{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e56f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24fe35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cdf2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "138a50e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|    _c0| _c1|\n",
      "+-------+----+\n",
      "|  Name |Age |\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.read.csv(r\"C:\\Users\\muhammad.helmy\\Documents\\Pyspark\\Book1.csv\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bc7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827a2f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BASSKLDBMMH.fleet.bassnet.no:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d1ab58fad0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0508ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_pyspark=spark.read.csv('book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa12f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|    _c0| _c1|\n",
      "+-------+----+\n",
      "|  Name |Age |\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dy_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0703541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6351ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be76ef23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Danny', Age ='31'),\n",
       " Row(Name ='Sunny', Age ='30'),\n",
       " Row(Name ='Gabriel', Age ='28')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40011d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- Age : string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4f0fd",
   "metadata": {},
   "source": [
    "- PySpark Dataframe\n",
    "- Reading the dataset\n",
    "- Checking the datatypes of the column \n",
    "- Selecting Columns and Indexing\n",
    "- Check Describe option similar to Pandas\n",
    "- Adding Columns \n",
    "- Droppping Columns\n",
    "- Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65c51184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fde5630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbfd8ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://BASSKLDBMMH.fleet.bassnet.no:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d1ab58fad0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c5e32f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |Age |\n",
      "+-------+----+\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##read the dataset\n",
    "df_pyspark=spark.read.option('header','true').csv('book1.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "567bdd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |Age |\n",
      "+-------+----+\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('Book1.csv',header = True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd6a2392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- Age : integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8640f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c31bdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name ', 'Age ']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "631b5868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name ='Danny', Age =31),\n",
       " Row(Name ='Sunny', Age =30),\n",
       " Row(Name ='Gabriel', Age =28)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da80b06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |Age |\n",
      "+-------+----+\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44e6db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Name |\n",
      "+-------+\n",
      "|  Danny|\n",
      "|  Sunny|\n",
      "|Gabriel|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "454ff195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  Name |\n",
      "+-------+\n",
      "|  Danny|\n",
      "|  Sunny|\n",
      "|Gabriel|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('Name ').show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c064ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |Age |\n",
      "+-------+----+\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name ', 'Age ']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f0fd627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name '>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86cddfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name ', 'string'), ('Age ', 'int')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72e6f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+\n",
      "|summary|Name |              Age |\n",
      "+-------+-----+------------------+\n",
      "|  count|    3|                 3|\n",
      "|   mean| NULL|29.666666666666668|\n",
      "| stddev| NULL|1.5275252316519465|\n",
      "|    min|Danny|                28|\n",
      "|    max|Sunny|                31|\n",
      "+-------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7f93ce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name : string, Age : int, Age in 2 years: int]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Adding Columns in data frame\n",
    "df_pyspark.withColumn('Age in 2 years', df_pyspark['Age ']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70c606a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.withColumn('Age in 2 years', df_pyspark['Age ']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef8d36dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------+\n",
      "|  Name |Age |Age in 2 years|\n",
      "+-------+----+--------------+\n",
      "|  Danny|  31|            33|\n",
      "|  Sunny|  30|            32|\n",
      "|Gabriel|  28|            30|\n",
      "+-------+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5de109c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |Age |\n",
      "+-------+----+\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Drop the columns\n",
    "df_pyspark.drop('Age in 2 years').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f29afc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.drop('Age in 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18b0f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|  Name |Age |\n",
      "+-------+----+\n",
      "|  Danny|  31|\n",
      "|  Sunny|  30|\n",
      "|Gabriel|  28|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b9c1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|New Name|Age |\n",
      "+--------+----+\n",
      "|   Danny|  31|\n",
      "|   Sunny|  30|\n",
      "| Gabriel|  28|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Rename the columns\n",
    "df_pyspark.withColumnRenamed('Name ','New Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46934e",
   "metadata": {},
   "source": [
    "### PySpark Handling Missing Values \n",
    "- Dropping Columns\n",
    "- Dropping Rows \n",
    "- Various Parameter in Dropping functoinalities \n",
    "- Handling Missing values by Mean, Median and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a96ec77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d161a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('Book2.csv',header=True,inferSchema=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f78d45a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       Name| age|Experience|Salary|\n",
      "+-----------+----+----------+------+\n",
      "|       Kris|  31|        10| 30000|\n",
      "|   Sudhardo|  30|         8| 25000|\n",
      "|       Goku|  29|         4| 20000|\n",
      "|SuperSaiyan|  24|         3| 20000|\n",
      "|       Paul|  21|         1| 15000|\n",
      "|     Vegeta|  23|         2| 18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|\n",
      "|       NULL|  34|        10| 38000|\n",
      "|       NULL|  36|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee3f52ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  31|        10| 30000|\n",
      "|  30|         8| 25000|\n",
      "|  29|         4| 20000|\n",
      "|  24|         3| 20000|\n",
      "|  21|         1| 15000|\n",
      "|  23|         2| 18000|\n",
      "|NULL|      NULL| 40000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##drop the columns \n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ed98c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       Name|age|Experience|Salary|\n",
      "+-----------+---+----------+------+\n",
      "|       Kris| 31|        10| 30000|\n",
      "|   Sudhardo| 30|         8| 25000|\n",
      "|       Goku| 29|         4| 20000|\n",
      "|SuperSaiyan| 24|         3| 20000|\n",
      "|       Paul| 21|         1| 15000|\n",
      "|     Vegeta| 23|         2| 18000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a0ee75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       Name| age|Experience|Salary|\n",
      "+-----------+----+----------+------+\n",
      "|       Kris|  31|        10| 30000|\n",
      "|   Sudhardo|  30|         8| 25000|\n",
      "|       Goku|  29|         4| 20000|\n",
      "|SuperSaiyan|  24|         3| 20000|\n",
      "|       Paul|  21|         1| 15000|\n",
      "|     Vegeta|  23|         2| 18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|\n",
      "|       NULL|  34|        10| 38000|\n",
      "|       NULL|  36|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### any==how \n",
    "df_pyspark.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8467f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       Name|age|Experience|Salary|\n",
      "+-----------+---+----------+------+\n",
      "|       Kris| 31|        10| 30000|\n",
      "|   Sudhardo| 30|         8| 25000|\n",
      "|       Goku| 29|         4| 20000|\n",
      "|SuperSaiyan| 24|         3| 20000|\n",
      "|       Paul| 21|         1| 15000|\n",
      "|     Vegeta| 23|         2| 18000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### any==how \n",
    "df_pyspark.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a3e85914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       Name| age|Experience|Salary|\n",
      "+-----------+----+----------+------+\n",
      "|       Kris|  31|        10| 30000|\n",
      "|   Sudhardo|  30|         8| 25000|\n",
      "|       Goku|  29|         4| 20000|\n",
      "|SuperSaiyan|  24|         3| 20000|\n",
      "|       Paul|  21|         1| 15000|\n",
      "|     Vegeta|  23|         2| 18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|\n",
      "|       NULL|  34|        10| 38000|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##threshold\n",
    "df_pyspark.na.drop(how=\"any\",thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f4e5f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       Name|age|Experience|Salary|\n",
      "+-----------+---+----------+------+\n",
      "|       Kris| 31|        10| 30000|\n",
      "|   Sudhardo| 30|         8| 25000|\n",
      "|       Goku| 29|         4| 20000|\n",
      "|SuperSaiyan| 24|         3| 20000|\n",
      "|       Paul| 21|         1| 15000|\n",
      "|     Vegeta| 23|         2| 18000|\n",
      "|       NULL| 34|        10| 38000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Subsets \n",
    "df_pyspark.na.drop(how=\"any\",subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d77c19ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          Name| age|Experience|Salary|\n",
      "+--------------+----+----------+------+\n",
      "|          Kris|  31|        10| 30000|\n",
      "|      Sudhardo|  30|         8| 25000|\n",
      "|          Goku|  29|         4| 20000|\n",
      "|   SuperSaiyan|  24|         3| 20000|\n",
      "|          Paul|  21|         1| 15000|\n",
      "|        Vegeta|  23|         2| 18000|\n",
      "|        Bilbao|NULL|      NULL| 40000|\n",
      "|Missing Values|  34|        10| 38000|\n",
      "|Missing Values|  36|      NULL|  NULL|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling the missing values \n",
    "df_pyspark.na.fill('Missing Values',['Experience','age','Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "807e88de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       Name| age|Experience|Salary|\n",
      "+-----------+----+----------+------+\n",
      "|       Kris|  31|        10| 30000|\n",
      "|   Sudhardo|  30|         8| 25000|\n",
      "|       Goku|  29|         4| 20000|\n",
      "|SuperSaiyan|  24|         3| 20000|\n",
      "|       Paul|  21|         1| 15000|\n",
      "|     Vegeta|  23|         2| 18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|\n",
      "|       NULL|  34|        10| 38000|\n",
      "|       NULL|  36|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cafa22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer (\n",
    "    inputCols=['age','Experience','Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age','Experience','Salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df3c679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "|       Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "|       Kris|  31|        10| 30000|         31|                10|         30000|\n",
      "|   Sudhardo|  30|         8| 25000|         30|                 8|         25000|\n",
      "|       Goku|  29|         4| 20000|         29|                 4|         20000|\n",
      "|SuperSaiyan|  24|         3| 20000|         24|                 3|         20000|\n",
      "|       Paul|  21|         1| 15000|         21|                 1|         15000|\n",
      "|     Vegeta|  23|         2| 18000|         23|                 2|         18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|         28|                 5|         40000|\n",
      "|       NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|       NULL|  36|      NULL|  NULL|         36|                 5|         25750|\n",
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df \n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8c44a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer (\n",
    "    inputCols=['age','Experience','Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age','Experience','Salary']]\n",
    ").setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ca4e713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "|       Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "|       Kris|  31|        10| 30000|         31|                10|         30000|\n",
      "|   Sudhardo|  30|         8| 25000|         30|                 8|         25000|\n",
      "|       Goku|  29|         4| 20000|         29|                 4|         20000|\n",
      "|SuperSaiyan|  24|         3| 20000|         24|                 3|         20000|\n",
      "|       Paul|  21|         1| 15000|         21|                 1|         15000|\n",
      "|     Vegeta|  23|         2| 18000|         23|                 2|         18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|         29|                 4|         40000|\n",
      "|       NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|       NULL|  36|      NULL|  NULL|         36|                 4|         20000|\n",
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e28d2b",
   "metadata": {},
   "source": [
    "### Pyspark Dataframes\n",
    "\n",
    "- Filter operation\n",
    "- &,|,==\n",
    "- ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3181a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a0082e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b5bb9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       Name| age|Experience|Salary|\n",
      "+-----------+----+----------+------+\n",
      "|       Kris|  31|        10| 30000|\n",
      "|   Sudhardo|  30|         8| 25000|\n",
      "|       Goku|  29|         4| 20000|\n",
      "|SuperSaiyan|  24|         3| 20000|\n",
      "|       Paul|  21|         1| 15000|\n",
      "|     Vegeta|  23|         2| 18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|\n",
      "|       NULL|  34|        10| 38000|\n",
      "|       NULL|  36|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('Book1.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fb233",
   "metadata": {},
   "source": [
    "### Filter Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0b519d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       Name|age|Experience|Salary|\n",
      "+-----------+---+----------+------+\n",
      "|       Goku| 29|         4| 20000|\n",
      "|SuperSaiyan| 24|         3| 20000|\n",
      "|       Paul| 21|         1| 15000|\n",
      "|     Vegeta| 23|         2| 18000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary of the people less than or equal to 20000\n",
    "df_pyspark.filter(\"Salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "11e1cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|       Name|age|\n",
      "+-----------+---+\n",
      "|       Goku| 29|\n",
      "|SuperSaiyan| 24|\n",
      "|       Paul| 21|\n",
      "|     Vegeta| 23|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Salary<=20000\").select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9d03d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       Name|age|Experience|Salary|\n",
      "+-----------+---+----------+------+\n",
      "|       Goku| 29|         4| 20000|\n",
      "|SuperSaiyan| 24|         3| 20000|\n",
      "|       Paul| 21|         1| 15000|\n",
      "|     Vegeta| 23|         2| 18000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['Salary']<=20000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "731e689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       Name|age|Experience|Salary|\n",
      "+-----------+---+----------+------+\n",
      "|       Goku| 29|         4| 20000|\n",
      "|SuperSaiyan| 24|         3| 20000|\n",
      "|       Paul| 21|         1| 15000|\n",
      "|     Vegeta| 23|         2| 18000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Salary']<=20000) & (df_pyspark['Salary']>=15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b73a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       Name| age|Experience|Salary|\n",
      "+-----------+----+----------+------+\n",
      "|       Kris|  31|        10| 30000|\n",
      "|   Sudhardo|  30|         8| 25000|\n",
      "|       Goku|  29|         4| 20000|\n",
      "|SuperSaiyan|  24|         3| 20000|\n",
      "|       Paul|  21|         1| 15000|\n",
      "|     Vegeta|  23|         2| 18000|\n",
      "|     Bilbao|NULL|      NULL| 40000|\n",
      "|       NULL|  34|        10| 38000|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Salary']<=20000) | (df_pyspark['Salary']>=15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "672ab0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|    Kris|  31|        10| 30000|\n",
      "|Sudhardo|  30|         8| 25000|\n",
      "|  Bilbao|NULL|      NULL| 40000|\n",
      "|    NULL|  34|        10| 38000|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a62b0",
   "metadata": {},
   "source": [
    "### Pyspark Groupby and Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550338b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe60e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Agg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c5af7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Agg</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e6c97b8a30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa531e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('Book3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de932e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+------+\n",
      "|  Name| Departments|salary|\n",
      "+------+------------+------+\n",
      "|  Sony|Data Science| 10000|\n",
      "|Toyota|         IOT|  5000|\n",
      "|Mahesh|    Big Data|  4000|\n",
      "| Krish|    Big Data|  4000|\n",
      "| Hakim|Data Science|  3000|\n",
      "|    JS|Data Science| 20000|\n",
      "|  Zara|         IOT| 10000|\n",
      "|Saiful|    Big Data|  5000|\n",
      "|  Boon|Data Science| 10000|\n",
      "| Honda|    Big Data|  2000|\n",
      "+------+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77cfd1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Departments: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64eb0bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|  Name|sum(salary)|\n",
      "+------+-----------+\n",
      "|  Sony|      10000|\n",
      "|  Zara|      10000|\n",
      "| Honda|       2000|\n",
      "| Krish|       4000|\n",
      "|    JS|      20000|\n",
      "|  Boon|      10000|\n",
      "|Toyota|       5000|\n",
      "| Hakim|       3000|\n",
      "|Saiful|       5000|\n",
      "|Mahesh|       4000|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Groupby\n",
    "### Grouped to find the maximum salary\n",
    "df_pyspark.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "72416779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|      15000|\n",
      "|    Big Data|      15000|\n",
      "|Data Science|      43000|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Groupby Departments which give maximum salary\n",
    "df_pyspark.groupBy('Departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc60fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| Departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|         IOT|     7500.0|\n",
      "|    Big Data|     3750.0|\n",
      "|Data Science|    10750.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b94b4a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| Departments|count|\n",
      "+------------+-----+\n",
      "|         IOT|    2|\n",
      "|    Big Data|    4|\n",
      "|Data Science|    4|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b73e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|      73000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8f6148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|  Name|max(salary)|\n",
      "+------+-----------+\n",
      "|  Sony|      10000|\n",
      "|  Zara|      10000|\n",
      "| Honda|       2000|\n",
      "| Krish|       4000|\n",
      "|    JS|      20000|\n",
      "|  Boon|      10000|\n",
      "|Toyota|       5000|\n",
      "| Hakim|       3000|\n",
      "|Saiful|       5000|\n",
      "|Mahesh|       4000|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a4fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Missing').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ad7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read The dataset\n",
    "training = spark.read.csv('test1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46b05e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5fce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de0da4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d220b10d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (997011921.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [18]\u001b[1;36m\u001b[0m\n\u001b[1;33m    [Age,Experience]----> new feature--->independent feature\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[Age,Experience]----> new feature--->independent featurefrom pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4993d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=[\"age\",\"Experience\"],outputCol=\"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "448a46f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "500c9437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+--------------------+\n",
      "|     Name|age|Experience|Salary|Independent Features|\n",
      "+---------+---+----------+------+--------------------+\n",
      "|    Krish| 31|        10| 30000|         [31.0,10.0]|\n",
      "|Sudhanshu| 30|         8| 25000|          [30.0,8.0]|\n",
      "|    Sunny| 29|         4| 20000|          [29.0,4.0]|\n",
      "|     Paul| 24|         3| 20000|          [24.0,3.0]|\n",
      "|   Harsha| 21|         1| 15000|          [21.0,1.0]|\n",
      "|  Shubham| 23|         2| 18000|          [23.0,2.0]|\n",
      "+---------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d847e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary', 'Independent Features']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39faebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"Salary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf075545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "559d7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='Salary')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40078e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-176.3341, 1320.1856])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Coefficients\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d94a78b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19812.064965197405"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Intercepts\n",
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "731d9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction\n",
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e153e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|Independent Features|Salary|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|          [21.0,1.0]| 15000|17429.234338747105|\n",
      "|         [31.0,10.0]| 30000| 27547.56380510443|\n",
      "+--------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb4e1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2440.8352668213374, 5957811.381290973)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5571b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
